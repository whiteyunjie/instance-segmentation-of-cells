{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "#from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#这里将dataset2改成dataset1即可读取dataset1中的数据\n",
    "train_list = sorted([os.path.join('dataset2/train/',img) for img in os.listdir('dataset2/train/')])\n",
    "trainGT_list = sorted([os.path.join('dataset2/train_GT/SEG/',img) for img in os.listdir('dataset2/train_GT/SEG/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset1则设为628，dataset2设为500\n",
    "imgsize = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadpro_img(file_names):\n",
    "    images = []\n",
    "    for file_name in file_names:\n",
    "        img = cv2.imread(file_name,-1)#读取时不做改变，默认参数1加载彩色图片\n",
    "        img = img.astype(np.uint8)\n",
    "        #img = Image.fromarray(img)\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = loadpro_img(train_list)\n",
    "trainGT_data = loadpro_img(trainGT_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图片one-hot编码及pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GT生成二值化图像mask\n",
    "trainGTbin = np.zeros(trainGT_data.shape)\n",
    "for i in range(len(trainGT_data)):\n",
    "    gt = trainGT_data[i].reshape((-1,))\n",
    "    index = np.argwhere(gt > 0)\n",
    "    #trainGTbin[i][index] = 1 \n",
    "    gtbin = trainGTbin[i].reshape((-1,))\n",
    "    gtbin[index] = 1\n",
    "    trainGTbin[i] = gtbin.reshape((imgsize,imgsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask换成one-hot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "mask = np.zeros((len(trainGTbin),2,imgsize,imgsize))\n",
    "for i in range(len(trainGTbin)):\n",
    "    enc = OneHotEncoder(categories='auto')\n",
    "    a=enc.fit_transform(trainGTbin[i].reshape((-1,1)))\n",
    "    label=a.toarray()\n",
    "    label1=label[:,0].reshape((imgsize,imgsize))\n",
    "    label2=label[:,1].reshape((imgsize,imgsize))\n",
    "    mask[i] = np.array([label1,label2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输入图像镜像pad\n",
    "data = np.zeros((len(train_data),1,imgsize+2*92,imgsize+2*92))\n",
    "for i in range(len(train_data)):\n",
    "    data[i] = np.pad(train_data[i],((92,92)),'symmetric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_tensor = torch.from_numpy(data)\n",
    "label_tensor = torch.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重写dataset，图片分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#重写dataset，图片分组\n",
    "data_transforms = transforms.Compose([\n",
    "        #transforms.Pad(92,padding_mode='symmetric'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5],[0.5])\n",
    "    ])\n",
    "datalabel_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self,imgs,labels,gt,transform_x=None,transform_y=None):\n",
    "        self.transform_x = transform_x\n",
    "        self.transform_y = transform_y\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.gt = gt\n",
    "    def __getitem__(self,index):\n",
    "        img = self.imgs[index]\n",
    "        img = img/255\n",
    "        img = (img-0.5)/0.5\n",
    "        #img = self.transform_x(img)\n",
    "        label = self.labels[index]\n",
    "        #label = self.transform_y(label)\n",
    "        return torch.from_numpy(img),torch.from_numpy(label),torch.from_numpy(self.gt[index])\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "train_dataset = myDataset(data,mask,trainGT_data,data_transforms,datalabel_transforms)\n",
    "dataloders = DataLoader(train_dataset,batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class convnet(nn.Module):\n",
    "    def __init__(self,inchannels,outchannels):\n",
    "        super(convnet,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(inchannels,outchannels,3),\n",
    "            nn.BatchNorm2d(outchannels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(outchannels,outchannels,3),\n",
    "            nn.BatchNorm2d(outchannels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myUnet,self).__init__()\n",
    "        #down_sample\n",
    "        self.convnet1 = convnet(1,64)\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.convnet2 = convnet(64,128)\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.convnet3 = convnet(128,256)\n",
    "        self.maxpool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.convnet4 = convnet(256,512)\n",
    "        self.maxpool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.convnet5 = convnet(512,1024)\n",
    "        \n",
    "        #up_sample\n",
    "        self.up1 = nn.ConvTranspose2d(1024,512,2,stride=2)\n",
    "        self.convnet6 = convnet(1024,512)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(512,256,2,stride=2)\n",
    "        self.convnet7 = convnet(512,256)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(256,128,2,stride=2)\n",
    "        self.convnet8 = convnet(256,128)\n",
    "        \n",
    "        self.up4 = nn.ConvTranspose2d(128,64,2,stride=2)\n",
    "        self.convnet9 = convnet(128,64)\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(64,2,1)\n",
    "    def forward(self,x):\n",
    "        x1 = self.convnet1(x)\n",
    "        x2 = self.convnet2(self.maxpool1(x1))\n",
    "        x3 = self.convnet3(self.maxpool2(x2))\n",
    "        x4 = self.convnet4(self.maxpool3(x3))\n",
    "        \n",
    "        x5 = self.convnet5(self.maxpool4(x4))\n",
    "        \n",
    "        xup1 = self.up1(x5)\n",
    "        pad = (x4.size(2)-xup1.size(2))//2\n",
    "        xcrop1 = x4[:,:,pad:pad+xup1.size(2),pad:pad+xup1.size(2)]\n",
    "        xcat1 = torch.cat([xcrop1,xup1],1)\n",
    "        x6 = self.convnet6(xcat1)\n",
    "        \n",
    "        xup2 = self.up2(x6)\n",
    "        pad = (x3.size(2)-xup2.size(2))//2\n",
    "        xcrop2 = x3[:,:,pad:pad+xup2.size(2),pad:pad+xup2.size(2)]\n",
    "        xcat2 = torch.cat([xcrop2,xup2],1)\n",
    "        x7 = self.convnet7(xcat2)\n",
    "        \n",
    "        xup3 = self.up3(x7)\n",
    "        pad = (x2.size(2)-xup3.size(2))//2\n",
    "        xcrop3 = x2[:,:,pad:pad+xup3.size(2),pad:pad+xup3.size(2)]\n",
    "        xcat3 = torch.cat([xcrop3,xup3],1)\n",
    "        x8 = self.convnet8(xcat3)\n",
    "        \n",
    "        xup4 = self.up4(x8)\n",
    "        pad = (x1.size(2)-xup4.size(2))//2\n",
    "        xcrop4 = x1[:,:,pad:pad+xup4.size(2),pad:pad+xup4.size(2)]\n",
    "        xcat4 = torch.cat([xcrop4,xup4],1)\n",
    "        x9 = self.convnet9(xcat4)\n",
    "        \n",
    "        xf = self.conv10(x9)\n",
    "        return xf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = myUnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 加载现有模型，则不需要下面的训练过程，可以直接开始评估\n",
    "model.load_state_dict(torch.load('unet2params1.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练参数的设计\n",
    "epoch_nums = 35\n",
    "#optimizer = torch.optim.SGD(model.parameters(),lr=1e-6,momentum=0.8)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "loss = nn.BCEWithLogitsLoss().cuda()\n",
    "batch_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:51<00:00,  1.39it/s]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 0\n",
      "loss: 0.2666672148874828\n",
      "acc: 0.8511354047619047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [01:54<00:00,  1.95s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 1\n",
      "loss: 0.2241946311578864\n",
      "acc: 0.8783200476190474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:21<00:00,  1.46s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 2\n",
      "loss: 0.20106244690361477\n",
      "acc: 0.8857747380952378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:49<00:00,  2.06s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 3\n",
      "loss: 0.18360234335774467\n",
      "acc: 0.8901962857142852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:39<00:00,  2.11s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 4\n",
      "loss: 0.16834300242009617\n",
      "acc: 0.8966801904761911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:48<00:00,  2.01s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 5\n",
      "loss: 0.15643310103388058\n",
      "acc: 0.8995805952380946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:31<00:00,  1.77s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 6\n",
      "loss: 0.14546752641243593\n",
      "acc: 0.9036394761904765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:39<00:00,  1.96s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 7\n",
      "loss: 0.13642989764256136\n",
      "acc: 0.9079555714285719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:18<00:00,  1.10it/s]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 8\n",
      "loss: 0.12863714318899883\n",
      "acc: 0.911835214285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [01:50<00:00,  1.64s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 9\n",
      "loss: 0.11816571280360222\n",
      "acc: 0.9190058809523807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:30<00:00,  1.02it/s]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 10\n",
      "loss: 0.11096080055549032\n",
      "acc: 0.923596119047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:29<00:00,  1.84s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 11\n",
      "loss: 0.10500690438562915\n",
      "acc: 0.9267613095238089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:17<00:00,  1.16s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 12\n",
      "loss: 0.09496035267199789\n",
      "acc: 0.9350543333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:30<00:00,  1.96s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 13\n",
      "loss: 0.08866490716380733\n",
      "acc: 0.9393232619047612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:21<00:00,  1.29s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 14\n",
      "loss: 0.08152453140133903\n",
      "acc: 0.9448032380952378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:04<00:00,  2.06s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 15\n",
      "loss: 0.07480077259242535\n",
      "acc: 0.9497113571428569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [01:52<00:00,  1.06s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 16\n",
      "loss: 0.06872488970735244\n",
      "acc: 0.9545202857142859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [02:46<00:00,  1.61s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 17\n",
      "loss: 0.06414900405243748\n",
      "acc: 0.9574474523809519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [03:40<00:00,  2.61s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 18\n",
      "loss: 0.05999473939161925\n",
      "acc: 0.9598781428571433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [03:56<00:00,  3.00s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 19\n",
      "loss: 0.054256148503295014\n",
      "acc: 0.9644102380952382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [03:59<00:00,  3.03s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 20\n",
      "loss: 0.051247499350990565\n",
      "acc: 0.9660927619047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [03:49<00:00,  2.75s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 21\n",
      "loss: 0.047971450812405066\n",
      "acc: 0.968096547619048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:13<00:00,  3.23s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 22\n",
      "loss: 0.04587424932313817\n",
      "acc: 0.9691277857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:45<00:00,  3.27s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 23\n",
      "loss: 0.04504803705605723\n",
      "acc: 0.9689228571428565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:45<00:00,  3.38s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 24\n",
      "loss: 0.04204334897388305\n",
      "acc: 0.9709939523809523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:32<00:00,  3.03s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 25\n",
      "loss: 0.03917756164446473\n",
      "acc: 0.9732229523809527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:18<00:00,  3.27s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 26\n",
      "loss: 0.03667912119999528\n",
      "acc: 0.975171880952381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:41<00:00,  2.33s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 27\n",
      "loss: 0.034648114283170016\n",
      "acc: 0.9762338095238089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:33<00:00,  3.13s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 28\n",
      "loss: 0.03311372834390828\n",
      "acc: 0.976861023809524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:40<00:00,  3.52s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 29\n",
      "loss: 0.03206446691460553\n",
      "acc: 0.9776954761904756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:15<00:00,  3.17s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 30\n",
      "loss: 0.030409898453702528\n",
      "acc: 0.978765547619048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:32<00:00,  2.97s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 31\n",
      "loss: 0.029706198966041916\n",
      "acc: 0.9791069761904764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:10<00:00,  3.52s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 32\n",
      "loss: 0.028936017326833235\n",
      "acc: 0.9793348571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:16<00:00,  3.34s/it]\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 33\n",
      "loss: 0.02805051693160619\n",
      "acc: 0.9798344285714284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:33<00:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 34\n",
      "loss: 0.026977916869024437\n",
      "acc: 0.9805693571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "losses = []\n",
    "accs = []\n",
    "jses = []\n",
    "for echo in range(epoch_nums):\n",
    "    train_loss = 0\n",
    "    train_js=0\n",
    "    acc = 0\n",
    "    n = 0\n",
    "    for img,label,gt in tqdm(dataloders):\n",
    "        img = Variable(img.float()).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "        out = model(img)\n",
    "        lossvalue = loss(out,label.float())\n",
    "        optimizer.zero_grad()\n",
    "        lossvalue.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += float(lossvalue)\n",
    "        #acc = 0\n",
    "        n += batch_size\n",
    "        #loss参考意义不大\n",
    "        if n >len(dataloders.dataset):\n",
    "            pred=out[0].argmax(0)\n",
    "            true=label[0].argmax(0)\n",
    "            accnum = (pred==true).sum()\n",
    "            acc += float(accnum)/(imgsize*imgsize)\n",
    "        else:\n",
    "            for j in range(batch_size):\n",
    "                pred = torch.sigmoid(out[j])\n",
    "                pred=pred.argmax(0)\n",
    "                true=label[j].argmax(0)\n",
    "                accnum = (pred==true).sum()\n",
    "                acc += float(accnum)/(imgsize*imgsize)\n",
    "        #jsvalue\n",
    "#         if n >len(dataloders.dataset):\n",
    "#             pred=out[0].argmax(0).cpu()\n",
    "#             pred = pred.numpy()\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             maxval,pred_img = cv2.connectedComponents(pred, 4, cv2.CV_32S)\n",
    "#             true=gt[0]\n",
    "#             _,score=Jaccard_eval(pred_img,true)\n",
    "#             train_js += score\n",
    "#         else:\n",
    "#             for j in range(batch_size):\n",
    "#                 pred=out[j].argmax(0).cpu()\n",
    "#                 pred = pred.numpy()\n",
    "#                 pred = pred.astype(np.uint8)\n",
    "#                 true=gt[j]\n",
    "#                 maxval,pred_img = cv2.connectedComponents(pred, 4, cv2.CV_32S)\n",
    "#                 _,score=Jaccard_eval(pred_img,true)\n",
    "#                 train_js += score\n",
    "    jses.append(acc/len(dataloders.dataset))   \n",
    "    losses.append(train_loss/len(dataloders))\n",
    "    print('echo:'+ ' '+str(echo))\n",
    "    print('loss:'+ ' '+str(train_loss/len(dataloders.dataset)))\n",
    "    print('acc:'+ ' '+str(acc/len(dataloders.dataset)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存训练模型\n",
    "torch.save(model.state_dict(),'unet2paramsn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jaccard相似度评估函数\n",
    "def get_onelabelmap(data,label):\n",
    "    index = np.argwhere(data==label)\n",
    "    sam = np.zeros(data.shape)\n",
    "    if len(index) is not 0:\n",
    "        for i in range(len(index)):\n",
    "            sam[index[i][0]][index[i][1]] = 1\n",
    "    sam = sam.astype(np.int32)#注意类型转换，否则无法进行与运算\n",
    "    return sam\n",
    "def get_fit_GTimgs(cell_pred,label,cell_gt):\n",
    "    #对于每个预测标签细胞，求与其匹配的gt细胞\n",
    "    fit_lists = []\n",
    "    Jaccard_lists = []\n",
    "    labels = np.unique(cell_pred)\n",
    "    cell_gt_map = get_onelabelmap(cell_gt,label)\n",
    "    if len(labels) is not 0:\n",
    "        for i in range(1,len(labels)):\n",
    "            cell_pred_map = get_onelabelmap(cell_pred,labels[i])\n",
    "            andmap=cell_pred_map&cell_gt_map\n",
    "            if np.sum(andmap)>0.5*np.sum(cell_gt_map):\n",
    "                a = np.sum(cell_pred_map&cell_gt_map)\n",
    "                b = np.sum(cell_pred_map|cell_gt_map)\n",
    "                fit_lists.append(labels[i])\n",
    "                Jaccard_lists.append(a/b)\n",
    "    return fit_lists,Jaccard_lists\n",
    "def Jaccard_eval(cell_pred,cell_gt):\n",
    "    #Jaccard相似度评估\n",
    "    labels_gt = np.unique(cell_gt)\n",
    "    JS_val = np.zeros((len(labels_gt)-1,))\n",
    "    for i in range(1,len(labels_gt)):\n",
    "        fit_lists,Jaccard_lists = get_fit_GTimgs(cell_pred,labels_gt[i],cell_gt)\n",
    "        if len(fit_lists) is not 0:\n",
    "             JS_val[i-1] = np.max(Jaccard_lists)\n",
    "    return JS_val,np.mean(JS_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后处理方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### watershed process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def watershed_process(mask):\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(mask,kernel,iterations=3)\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(mask,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.592*dist_transform.max(),255,0)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown == 1] = 0\n",
    "    #predpro = 255 - predpro\n",
    "    rgb = cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "    markers2 = cv2.watershed(rgb,markers)\n",
    "    newmark=markers2\n",
    "    newmark[markers2==-1] = 1\n",
    "    newmark = newmark-1\n",
    "    return newmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kluster_proess(mask):\n",
    "    #maxval,pred_img,_,_ = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S)\n",
    "    pred_img = watershed_process(mask)\n",
    "    zonelabels = np.unique(pred_img)\n",
    "    imgpro = np.zeros(mask.shape,np.uint8)\n",
    "    curnum = 0\n",
    "    for i in range(1,len(zonelabels)):\n",
    "        zone = np.zeros(mask.shape,np.uint8)\n",
    "        zone[pred_img==i]=1\n",
    "        index = np.argwhere(pred_img==i)\n",
    "        # plt.imshow(zone)\n",
    "        # plt.show()\n",
    "        #erode\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        img_erode = cv2.erode(zone,kernel,iterations = 20)\n",
    "        # plt.imshow(img_erode)\n",
    "        # plt.show()\n",
    "\n",
    "        #clusters\n",
    "        maxval,curzone,_,centorids = cv2.connectedComponentsWithStats(img_erode, 4, cv2.CV_32S)\n",
    "        curlabels = np.unique(curzone)\n",
    "        kclasses = len(curlabels)-1\n",
    "\n",
    "        flags = centorids[1:,:]\n",
    "        if len(flags)>0:\n",
    "            dataxy = index.astype(np.float32)\n",
    "            clf = KMeans(n_clusters=kclasses,init=flags,n_init=1,tol=1e-6)\n",
    "            clf.fit(dataxy)\n",
    "            clf.labels_ += 1 #最小标签是0\n",
    "\n",
    "            clf.labels_ += curnum #防止标签重复\n",
    "            for j in range(len(index)):\n",
    "                imgpro[index[j,0]][index[j,1]] = clf.labels_[j]\n",
    "            curnum = np.max(clf.labels_)\n",
    "        else:\n",
    "            for j in range(len(index)):\n",
    "                imgpro[index[j,0]][index[j,1]] = curnum + 1\n",
    "            curnum = 1\n",
    "            \n",
    "        #print(curnum)\n",
    "    #plt.imshow(imgpro)\n",
    "    #plt.show()\n",
    "    return imgpro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:1/168, score: 0.3382\n",
      "image:2/168, score: 0.1950\n",
      "image:3/168, score: 0.1930\n",
      "image:4/168, score: 0.6099\n",
      "image:5/168, score: 0.3090\n",
      "image:6/168, score: 0.1762\n",
      "image:7/168, score: 0.2953\n",
      "image:8/168, score: 0.0812\n",
      "image:9/168, score: 0.0755\n",
      "image:10/168, score: 0.5223\n",
      "image:11/168, score: 0.1499\n",
      "image:12/168, score: 0.1492\n",
      "image:13/168, score: 0.4380\n",
      "image:14/168, score: 0.3157\n",
      "image:15/168, score: 0.2952\n",
      "image:16/168, score: 0.7331\n",
      "image:17/168, score: 0.5484\n",
      "image:18/168, score: 0.4328\n",
      "image:19/168, score: 0.3599\n",
      "image:20/168, score: 0.3231\n",
      "image:21/168, score: 0.1472\n",
      "image:22/168, score: 0.1750\n",
      "image:23/168, score: 0.1276\n",
      "image:24/168, score: 0.3813\n",
      "image:25/168, score: 0.0638\n",
      "image:26/168, score: 0.3175\n",
      "image:27/168, score: 0.0693\n",
      "image:28/168, score: 0.2614\n",
      "image:29/168, score: 0.0568\n",
      "image:30/168, score: 0.5725\n",
      "image:31/168, score: 0.4809\n",
      "image:32/168, score: 0.3160\n",
      "image:33/168, score: 0.0509\n",
      "image:34/168, score: 0.0813\n",
      "image:35/168, score: 0.1948\n",
      "image:36/168, score: 0.1485\n",
      "image:37/168, score: 0.0487\n",
      "image:38/168, score: 0.1738\n",
      "image:39/168, score: 0.2168\n",
      "image:40/168, score: 0.0698\n",
      "image:41/168, score: 0.1935\n",
      "image:42/168, score: 0.0689\n",
      "image:43/168, score: 0.2233\n",
      "image:44/168, score: 0.2157\n",
      "image:45/168, score: 0.1275\n",
      "image:46/168, score: 0.1750\n",
      "image:47/168, score: 0.2151\n",
      "image:48/168, score: 0.2925\n",
      "image:49/168, score: 0.1280\n",
      "image:50/168, score: 0.0573\n",
      "image:51/168, score: 0.2609\n",
      "image:52/168, score: 0.0824\n",
      "image:53/168, score: 0.0612\n",
      "image:54/168, score: 0.0620\n",
      "image:55/168, score: 0.0615\n",
      "image:56/168, score: 0.1501\n",
      "image:57/168, score: 0.4230\n",
      "image:58/168, score: 0.2630\n",
      "image:59/168, score: 0.1193\n",
      "image:60/168, score: 0.0955\n",
      "image:61/168, score: 0.1937\n",
      "image:62/168, score: 0.0531\n",
      "image:63/168, score: 0.2417\n",
      "image:64/168, score: 0.1765\n",
      "image:65/168, score: 0.3979\n",
      "image:66/168, score: 0.4112\n",
      "image:67/168, score: 0.1280\n",
      "image:68/168, score: 0.1878\n",
      "image:69/168, score: 0.1673\n",
      "image:70/168, score: 0.1927\n",
      "image:71/168, score: 0.1481\n",
      "image:72/168, score: 0.0804\n",
      "image:73/168, score: 0.1762\n",
      "image:74/168, score: 0.1610\n",
      "image:75/168, score: 0.2440\n",
      "image:76/168, score: 0.2602\n",
      "image:77/168, score: 0.2625\n",
      "image:78/168, score: 0.0537\n",
      "image:79/168, score: 0.0651\n",
      "image:80/168, score: 0.1380\n",
      "image:81/168, score: 0.0804\n",
      "image:82/168, score: 0.1250\n",
      "image:83/168, score: 0.0881\n",
      "image:84/168, score: 0.1928\n",
      "image:85/168, score: 0.1748\n",
      "image:86/168, score: 0.2409\n",
      "image:87/168, score: 0.1938\n",
      "image:88/168, score: 0.0651\n",
      "image:89/168, score: 0.0593\n",
      "image:90/168, score: 0.3792\n",
      "image:91/168, score: 0.1924\n",
      "image:92/168, score: 0.1760\n",
      "image:93/168, score: 0.1621\n",
      "image:94/168, score: 0.2621\n",
      "image:95/168, score: 0.1487\n",
      "image:96/168, score: 0.2144\n",
      "image:97/168, score: 0.7856\n",
      "image:98/168, score: 0.8037\n",
      "image:99/168, score: 0.6249\n",
      "image:100/168, score: 0.1671\n",
      "image:101/168, score: 0.8581\n",
      "image:102/168, score: 0.2902\n",
      "image:103/168, score: 0.5249\n",
      "image:104/168, score: 0.4680\n",
      "image:105/168, score: 0.4308\n",
      "image:106/168, score: 0.5969\n",
      "image:107/168, score: 0.3699\n",
      "image:108/168, score: 0.6639\n",
      "image:109/168, score: 0.6317\n",
      "image:110/168, score: 0.1723\n",
      "image:111/168, score: 0.5277\n",
      "image:112/168, score: 0.0865\n",
      "image:113/168, score: 0.3967\n",
      "image:114/168, score: 0.1663\n",
      "image:115/168, score: 0.1367\n",
      "image:116/168, score: 0.2391\n",
      "image:117/168, score: 0.1790\n",
      "image:118/168, score: 0.3126\n",
      "image:119/168, score: 0.4793\n",
      "image:120/168, score: 0.3830\n",
      "image:121/168, score: 0.1361\n",
      "image:122/168, score: 0.1904\n",
      "image:123/168, score: 0.2932\n",
      "image:124/168, score: 0.0749\n",
      "image:125/168, score: 0.4333\n",
      "image:126/168, score: 0.2652\n",
      "image:127/168, score: 0.2912\n",
      "image:128/168, score: 0.2222\n",
      "image:129/168, score: 0.1015\n",
      "image:130/168, score: 0.1939\n",
      "image:131/168, score: 0.1401\n",
      "image:132/168, score: 0.1759\n",
      "image:133/168, score: 0.2444\n",
      "image:134/168, score: 0.0574\n",
      "image:135/168, score: 0.1761\n",
      "image:136/168, score: 0.0685\n",
      "image:137/168, score: 0.1919\n",
      "image:138/168, score: 0.1098\n",
      "image:139/168, score: 0.2388\n",
      "image:140/168, score: 0.1772\n",
      "image:141/168, score: 0.1615\n",
      "image:142/168, score: 0.4673\n",
      "image:143/168, score: 0.0649\n",
      "image:144/168, score: 0.1923\n",
      "image:145/168, score: 0.1074\n",
      "image:146/168, score: 0.1015\n",
      "image:147/168, score: 0.0656\n",
      "image:148/168, score: 0.1920\n",
      "image:149/168, score: 0.1286\n",
      "image:150/168, score: 0.1942\n",
      "image:151/168, score: 0.1756\n",
      "image:152/168, score: 0.1950\n",
      "image:153/168, score: 0.3334\n",
      "image:154/168, score: 0.2543\n",
      "image:155/168, score: 0.0542\n",
      "image:156/168, score: 0.1871\n",
      "image:157/168, score: 0.2186\n",
      "image:158/168, score: 0.1612\n",
      "image:159/168, score: 0.0488\n",
      "image:160/168, score: 0.1587\n",
      "image:161/168, score: 0.3816\n",
      "image:162/168, score: 0.3226\n",
      "image:163/168, score: 0.3226\n",
      "image:164/168, score: 0.1743\n",
      "image:165/168, score: 0.2751\n",
      "image:166/168, score: 0.2608\n",
      "image:167/168, score: 0.2733\n",
      "image:168/168, score: 0.1349\n",
      "final score: 0.23779\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_all = []\n",
    "score_all = []\n",
    "isval = True #true表明用来预测，否则就是验证正确率\n",
    "i = 0\n",
    "for img,label,gt in train_dataset:\n",
    "    img = img.reshape((1,1,684,684))\n",
    "    img = Variable(img.float()).cuda()\n",
    "    label = Variable(label).cuda()\n",
    "    orimg = img\n",
    "    with torch.no_grad():\n",
    "        testout = model(img)\n",
    "        testout = torch.sigmoid(testout)\n",
    "    #testloss = loss(testout,label)\n",
    "    pred = testout[0].argmax(0).cpu()\n",
    "    pred = pred.numpy()\n",
    "    pred = pred.astype(np.uint8)\n",
    "    \n",
    "    #pred_img = kluster_proess(pred)\n",
    "    #pred_img = watershed_process(pred)\n",
    "    maxval,pred_img = cv2.connectedComponents(pred, 4, cv2.CV_32S)\n",
    "    pred_all.append(pred_img)\n",
    "    if isval:\n",
    "        true = trainGT_data[i]\n",
    "        _,score = Jaccard_eval(pred_img,true)\n",
    "        score_all.append(score)\n",
    "        print('image:{}/168, score: {:.4f}'.format(i+1,score))\n",
    "    i = i+1\n",
    "print('final score: %.5f'%np.mean(score_all))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存储路径，需要先建好文件夹，否则会报错\n",
    "result_path = 'dataset2/test_RES'\n",
    "test_list = sorted([os.path.join('dataset2/test/',img) for img in os.listdir('dataset2/test/')])\n",
    "test_data = loadpro_img(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datapro = np.zeros((len(test_data),1,684,684))\n",
    "for i in range(len(test_data)):\n",
    "    test_datapro[i] = np.pad(test_data[i],((92,92)),'symmetric')\n",
    "    test_datapro[i] = test_datapro[i]/255.0\n",
    "    test_datapro[i] = (test_datapro[i]-0.5)/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datapro = torch.from_numpy(test_datapro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:1/6\n",
      "image:2/6\n",
      "image:3/6\n",
      "image:4/6\n",
      "image:5/6\n",
      "image:6/6\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_all=[]\n",
    "i = 0\n",
    "for index,img in enumerate(test_datapro):\n",
    "    img = img.reshape((1,1,684,684))\n",
    "    img = Variable(img.float()).cuda()\n",
    "    with torch.no_grad():\n",
    "        testout = model(img)\n",
    "        testout = torch.sigmoid(testout)\n",
    "    #testloss = loss(testout,label)\n",
    "    predtry = testout[0][0].cpu()\n",
    "    predtry = predtry.numpy()*255\n",
    "    predtry = predtry.astype(np.uint8)\n",
    "    pred = testout[0].argmax(0).cpu()\n",
    "    pred = pred.numpy()\n",
    "    pred = pred.astype(np.uint8)\n",
    "    \n",
    "    ## 可以选择不同的后处理方法\n",
    "    #pred_img = kluster_proess(pred)\n",
    "    pred_img = watershed_process(pred)\n",
    "    #maxval,pred_img = cv2.connectedComponents(pred, 4, cv2.CV_32S)\n",
    "    imageio.imwrite(os.path.join(result_path, 'mask{:0>3d}.tif'.format(index)),pred_img.astype(np.uint16))\n",
    "    pred_all.append(pred_img)\n",
    "    i = i+1\n",
    "    print('image:{}/6'.format(i))\n",
    "print('finish')    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "238px",
    "left": "637.57px",
    "right": "20px",
    "top": "120px",
    "width": "549px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
